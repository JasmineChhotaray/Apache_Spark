# Apache_Spark
working with Big Data using pyspark

# 1. Udemy Course: Taming Big Data with Apache Spark and Python
Concepts Learned:
1. Usage of Spark's Resilient Distributed Datasets to process and analyze large data sets.
2. Usage of Spark SQL, DataFrames and Datasets.
3. Breadth First Search (BFS) - Degrees of Separation


# 2. PySpark: An interface for Apache Spark in Python
Concepts Learned:
1. Exploratory Data Analysis at scale using PySpark.
2. Databricks: Cloud-Based Data Engineering tool to process huge amount of data distributed across multiple clusters or parallel procesing
